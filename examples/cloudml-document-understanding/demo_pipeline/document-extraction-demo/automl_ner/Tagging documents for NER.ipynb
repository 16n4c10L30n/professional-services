{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install --upgrade httplib2\n",
    "!pip3 install --upgrade requests\n",
    "!pip3 install nltk\n",
    "!pip3 install pandas\n",
    "!pip3 install regex\n",
    "!pip3 install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip3 install --user --upgrade httplib2\n",
    "!pip3 install --user --upgrade requests\n",
    "!pip3 install --user nltk\n",
    "!pip3 install --user pandas\n",
    "!pip3 install --user regex\n",
    "!pip3 install --user tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip3 install --upgrade google-cloud-storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip3 install --upgrade google-cloud-bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import regex\n",
    "import time\n",
    "import math\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import storage\n",
    "from io import BytesIO, StringIO\n",
    "import nltk\n",
    "from pandas.io import gbq\n",
    "from tensorflow.python.lib.io import file_io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#folder_json_all = 'gs://pdf-processing-219114/patents_train_fprost/json'\n",
    "folder_json_all = 'gs://pdf-processing-219114/patents_all_english/json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SERVICE_ACCOUNT_PATH = os.path.join(\n",
    "        os.getcwd(),\n",
    "        '../',\n",
    "        '0_key/pdf-processing-apikey2.json')\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = SERVICE_ACCOUNT_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pull OCR data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import logging\n",
    "from tensorflow.python.lib.io import file_io\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def vis_b_v1p2_json_path_to_text(json_path):\n",
    "  \"\"\"get text from a beta v1p2 vision api document text detection json\n",
    "\n",
    "  get document text from a google cloud vision API v1p2 document text detection\n",
    "    call output json, where pages are joined by newlines. return a string.\n",
    "\n",
    "  Args:\n",
    "    json_path: gs:// uri or local file path to a .json file created by\n",
    "      GCP vision API beta v1p2 document text extraction\n",
    "\n",
    "  Returns:\n",
    "    string of text from the .json, where pages are joined with /n\n",
    "  \"\"\"\n",
    "\n",
    "  logger.debug('reading json file %s', json_path)\n",
    "\n",
    "  raw_json = file_io.read_file_to_string(json_path)\n",
    "  dict_json = ast.literal_eval(raw_json)  # json to dict\n",
    "  full_text = []\n",
    "\n",
    "  for response in dict_json['responses']:\n",
    "    if 'fullTextAnnotation' in response.keys():\n",
    "      if 'text' in response['fullTextAnnotation'].keys():\n",
    "        full_text.append(response['fullTextAnnotation']['text'])\n",
    "      else:\n",
    "        logger.debug('%s has a fullTextAnnotation entry without a text field',\n",
    "                     json_path)\n",
    "        full_text.append('')\n",
    "    else:\n",
    "      logger.debug('%s has a response with no fullTextAnnotation field',\n",
    "                   json_path)\n",
    "      full_text.append('')\n",
    "\n",
    "  full_text = '\\n'.join(full_text)\n",
    "  return full_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content(gcs_path):\n",
    "    match = re.match(r'gs://([^/]+)/(.+)', gcs_path) # split bucket/path\n",
    "    bucket_name = match.group(1)\n",
    "    prefix = match.group(2)\n",
    "    client = storage.Client()\n",
    "    content_dict = {}  \n",
    "    bucket = client.get_bucket(bucket_name)\n",
    "\n",
    "    blob_list = list(bucket.list_blobs(prefix=prefix))\n",
    "    for blob in blob_list:\n",
    "        gcs_uris_list = []\n",
    "        JSON_PATH = os.path.join('gs://', blob.bucket.name, blob.name)\n",
    "        content_dict[JSON_PATH] = vis_b_v1p2_json_path_to_text(JSON_PATH)\n",
    "    return content_dict     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_dict = get_content(folder_json_all)\n",
    "\n",
    "pdf_df = pd.DataFrame.from_dict(content_dict, orient='index').reset_index()\n",
    "pdf_df.columns = ['pdf_uri', 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(196, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_df['filename'] = pdf_df['pdf_uri'].map(lambda x: os.path.basename(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pdf_uri</th>\n",
       "      <th>text</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gs://pdf-processing-219114/patents_all_english...</td>\n",
       "      <td>US010136408B1\\n(12) United States Patent\\nGree...</td>\n",
       "      <td>us_001.output-1-to-1.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gs://pdf-processing-219114/patents_all_english...</td>\n",
       "      <td>US010143012B2\\n(12) United States Patent\\nStat...</td>\n",
       "      <td>us_047.output-1-to-1.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gs://pdf-processing-219114/patents_all_english...</td>\n",
       "      <td>Europäisches\\nPatentamt\\nEuropean\\nPatent Offi...</td>\n",
       "      <td>Espacenet_En51.output-1-to-1.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gs://pdf-processing-219114/patents_all_english...</td>\n",
       "      <td>Europäisches\\nPatentamt\\nEuropean\\nPatent Offi...</td>\n",
       "      <td>Espacenet_En38.output-1-to-1.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gs://pdf-processing-219114/patents_all_english...</td>\n",
       "      <td>US010142921B2\\n(12) United States Patent\\nMcCa...</td>\n",
       "      <td>us_078.output-1-to-1.json</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             pdf_uri  \\\n",
       "0  gs://pdf-processing-219114/patents_all_english...   \n",
       "1  gs://pdf-processing-219114/patents_all_english...   \n",
       "2  gs://pdf-processing-219114/patents_all_english...   \n",
       "3  gs://pdf-processing-219114/patents_all_english...   \n",
       "4  gs://pdf-processing-219114/patents_all_english...   \n",
       "\n",
       "                                                text  \\\n",
       "0  US010136408B1\\n(12) United States Patent\\nGree...   \n",
       "1  US010143012B2\\n(12) United States Patent\\nStat...   \n",
       "2  Europäisches\\nPatentamt\\nEuropean\\nPatent Offi...   \n",
       "3  Europäisches\\nPatentamt\\nEuropean\\nPatent Offi...   \n",
       "4  US010142921B2\\n(12) United States Patent\\nMcCa...   \n",
       "\n",
       "                            filename  \n",
       "0          us_001.output-1-to-1.json  \n",
       "1          us_047.output-1-to-1.json  \n",
       "2  Espacenet_En51.output-1-to-1.json  \n",
       "3  Espacenet_En38.output-1-to-1.json  \n",
       "4          us_078.output-1-to-1.json  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract answer key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_path = \"gs://input_data_pdf/truth_data_feb182019.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bucket_blob(full_path):\n",
    "    match = re.match(r'gs://([^/]+)/(.+)', full_path)\n",
    "    bucket_name = match.group(1)\n",
    "    blob_name = match.group(2)\n",
    "    return bucket_name, blob_name\n",
    "\n",
    "def download_string(full_path, service_account):\n",
    "  storage_client = storage.Client.from_service_account_json(service_account)\n",
    "  bucket_name, path = get_bucket_blob(full_path)\n",
    "  bucket = storage_client.get_bucket(bucket_name)\n",
    "  blob = bucket.blob(path)\n",
    "  byte_stream = BytesIO()\n",
    "  blob.download_to_file(byte_stream)\n",
    "  byte_stream.seek(0)\n",
    "  return byte_stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_byte_stream = download_string(truth_path, SERVICE_ACCOUNT_PATH)\n",
    "df_truth = pd.read_csv(truth_byte_stream, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "found = 0\n",
    "not_found =0\n",
    "for _file in list(pdf_df['pdf_uri']):\n",
    "    _file = os.path.basename(_file).replace('.output-1-to-1.json', '.pdf')\n",
    "    if _file not in list(df_truth['file_name']):\n",
    "        print (_file)\n",
    "        not_found += 1\n",
    "    else:\n",
    "        found += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "196.0\n"
     ]
    }
   ],
   "source": [
    "print((float(not_found)/(not_found + found)))\n",
    "print(float(found))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve relevant fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>file_type</th>\n",
       "      <th>publication_date_dirty</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>classification_1_dirty</th>\n",
       "      <th>classification_1</th>\n",
       "      <th>classification_2_dirty</th>\n",
       "      <th>classification_2</th>\n",
       "      <th>application_number_dirty</th>\n",
       "      <th>application_number</th>\n",
       "      <th>filing_date</th>\n",
       "      <th>priority</th>\n",
       "      <th>representative</th>\n",
       "      <th>applicant</th>\n",
       "      <th>inventor</th>\n",
       "      <th>titleFL</th>\n",
       "      <th>titleSL</th>\n",
       "      <th>abstractFL</th>\n",
       "      <th>publication_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>us_001.pdf</td>\n",
       "      <td>US</td>\n",
       "      <td>Nov. 20, 2018</td>\n",
       "      <td>Nov. 20, 2018</td>\n",
       "      <td>H04W 64/00</td>\n",
       "      <td>H04W 64/00</td>\n",
       "      <td>H04W 64/003</td>\n",
       "      <td>H04W 64/003</td>\n",
       "      <td>679,694</td>\n",
       "      <td>679,694</td>\n",
       "      <td>Aug. 17, 2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Colby Green</td>\n",
       "      <td>Colby Green</td>\n",
       "      <td>DETERMINING HIGH VALUE</td>\n",
       "      <td>GEOGRAPHIC LOCATIONS</td>\n",
       "      <td>The present invention is a method and system o...</td>\n",
       "      <td>10,136,408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>us_002.pdf</td>\n",
       "      <td>US</td>\n",
       "      <td>Nov. 20, 2018</td>\n",
       "      <td>Nov. 20, 2018</td>\n",
       "      <td>H04W 36/18</td>\n",
       "      <td>H04W 36/18</td>\n",
       "      <td>H04W 36/0022</td>\n",
       "      <td>H04W 36/0022</td>\n",
       "      <td>599,409</td>\n",
       "      <td>599,409</td>\n",
       "      <td>May. 18, 2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Essential Products, Inc.</td>\n",
       "      <td>Mara Clair Segal</td>\n",
       "      <td>MEDIA AND COMMUNICATIONS IN A</td>\n",
       "      <td>CONNECTED ENVIRONMENT</td>\n",
       "      <td>Switching the providing of a conversation amon...</td>\n",
       "      <td>10,136,364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>us_003.pdf</td>\n",
       "      <td>US</td>\n",
       "      <td>*Nov. 20, 2018</td>\n",
       "      <td>Nov. 20, 2018</td>\n",
       "      <td>H04W 12/12</td>\n",
       "      <td>H04W 12/12</td>\n",
       "      <td>H04W 12/12</td>\n",
       "      <td>H04W 12/12</td>\n",
       "      <td>920,213</td>\n",
       "      <td>920,213</td>\n",
       "      <td>Mar. 13, 2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United Services Automobile</td>\n",
       "      <td>Amanda S. Fernandez</td>\n",
       "      <td>LOCATION VERIFICATION BASED ON</td>\n",
       "      <td>ENVIRONMENTAL SENSOR DATA</td>\n",
       "      <td>Techniques are described for determining and/o...</td>\n",
       "      <td>10,136,327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>us_004.pdf</td>\n",
       "      <td>US</td>\n",
       "      <td>Nov. 20, 2018</td>\n",
       "      <td>Nov. 20, 2018</td>\n",
       "      <td>H04W 40/02</td>\n",
       "      <td>H04W 40/02</td>\n",
       "      <td>H04W 12/06</td>\n",
       "      <td>H04W 12/06</td>\n",
       "      <td>628,883</td>\n",
       "      <td>628,883</td>\n",
       "      <td>Jun. 21, 2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AT&amp;T INTELLECTUAL</td>\n",
       "      <td>Paul R. Hancock</td>\n",
       "      <td>AUTHENTICATION DEVICE SELECTION</td>\n",
       "      <td>TO FACILITATE AUTHENTICATION VIA AN</td>\n",
       "      <td>Steering an authentication request to a determ...</td>\n",
       "      <td>10,136,318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>us_005.pdf</td>\n",
       "      <td>US</td>\n",
       "      <td>Nov. 20, 2018</td>\n",
       "      <td>Nov. 20, 2018</td>\n",
       "      <td>H04W 4/80</td>\n",
       "      <td>H04W 4/80</td>\n",
       "      <td>H04W 4/80</td>\n",
       "      <td>H04W 4/80</td>\n",
       "      <td>625,786</td>\n",
       "      <td>625,786</td>\n",
       "      <td>Jun. 16, 2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MICROSOFT TECHNOLOGY</td>\n",
       "      <td>Dikla Dotan-Cohen</td>\n",
       "      <td>SIGNAL SHARING BETWEEN TRUSTED</td>\n",
       "      <td>GROUPS OF DEVICES</td>\n",
       "      <td>Aspects of the technology described herein ide...</td>\n",
       "      <td>10,136,290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    file_name file_type publication_date_dirty publication_date  \\\n",
       "0  us_001.pdf        US          Nov. 20, 2018    Nov. 20, 2018   \n",
       "1  us_002.pdf        US          Nov. 20, 2018    Nov. 20, 2018   \n",
       "2  us_003.pdf        US         *Nov. 20, 2018    Nov. 20, 2018   \n",
       "3  us_004.pdf        US          Nov. 20, 2018    Nov. 20, 2018   \n",
       "4  us_005.pdf        US          Nov. 20, 2018    Nov. 20, 2018   \n",
       "\n",
       "  classification_1_dirty classification_1 classification_2_dirty  \\\n",
       "0             H04W 64/00       H04W 64/00            H04W 64/003   \n",
       "1             H04W 36/18       H04W 36/18           H04W 36/0022   \n",
       "2             H04W 12/12       H04W 12/12             H04W 12/12   \n",
       "3             H04W 40/02       H04W 40/02             H04W 12/06   \n",
       "4              H04W 4/80        H04W 4/80              H04W 4/80   \n",
       "\n",
       "  classification_2 application_number_dirty application_number    filing_date  \\\n",
       "0      H04W 64/003                  679,694            679,694  Aug. 17, 2017   \n",
       "1     H04W 36/0022                  599,409            599,409  May. 18, 2017   \n",
       "2       H04W 12/12                  920,213            920,213  Mar. 13, 2018   \n",
       "3       H04W 12/06                  628,883            628,883  Jun. 21, 2017   \n",
       "4        H04W 4/80                  625,786            625,786  Jun. 16, 2017   \n",
       "\n",
       "  priority representative                   applicant             inventor  \\\n",
       "0      NaN            NaN                 Colby Green          Colby Green   \n",
       "1      NaN            NaN    Essential Products, Inc.     Mara Clair Segal   \n",
       "2      NaN            NaN  United Services Automobile  Amanda S. Fernandez   \n",
       "3      NaN            NaN           AT&T INTELLECTUAL      Paul R. Hancock   \n",
       "4      NaN            NaN        MICROSOFT TECHNOLOGY    Dikla Dotan-Cohen   \n",
       "\n",
       "                           titleFL                              titleSL  \\\n",
       "0           DETERMINING HIGH VALUE                 GEOGRAPHIC LOCATIONS   \n",
       "1    MEDIA AND COMMUNICATIONS IN A                CONNECTED ENVIRONMENT   \n",
       "2   LOCATION VERIFICATION BASED ON            ENVIRONMENTAL SENSOR DATA   \n",
       "3  AUTHENTICATION DEVICE SELECTION  TO FACILITATE AUTHENTICATION VIA AN   \n",
       "4   SIGNAL SHARING BETWEEN TRUSTED                    GROUPS OF DEVICES   \n",
       "\n",
       "                                          abstractFL publication_number  \n",
       "0  The present invention is a method and system o...         10,136,408  \n",
       "1  Switching the providing of a conversation amon...         10,136,364  \n",
       "2  Techniques are described for determining and/o...         10,136,327  \n",
       "3  Steering an authentication request to a determ...         10,136,318  \n",
       "4  Aspects of the technology described herein ide...         10,136,290  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_truth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pdf_uri</th>\n",
       "      <th>text</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gs://pdf-processing-219114/patents_all_english...</td>\n",
       "      <td>US010136408B1\\n(12) United States Patent\\nGree...</td>\n",
       "      <td>us_001.output-1-to-1.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gs://pdf-processing-219114/patents_all_english...</td>\n",
       "      <td>US010143012B2\\n(12) United States Patent\\nStat...</td>\n",
       "      <td>us_047.output-1-to-1.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gs://pdf-processing-219114/patents_all_english...</td>\n",
       "      <td>Europäisches\\nPatentamt\\nEuropean\\nPatent Offi...</td>\n",
       "      <td>Espacenet_En51.output-1-to-1.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gs://pdf-processing-219114/patents_all_english...</td>\n",
       "      <td>Europäisches\\nPatentamt\\nEuropean\\nPatent Offi...</td>\n",
       "      <td>Espacenet_En38.output-1-to-1.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gs://pdf-processing-219114/patents_all_english...</td>\n",
       "      <td>US010142921B2\\n(12) United States Patent\\nMcCa...</td>\n",
       "      <td>us_078.output-1-to-1.json</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             pdf_uri  \\\n",
       "0  gs://pdf-processing-219114/patents_all_english...   \n",
       "1  gs://pdf-processing-219114/patents_all_english...   \n",
       "2  gs://pdf-processing-219114/patents_all_english...   \n",
       "3  gs://pdf-processing-219114/patents_all_english...   \n",
       "4  gs://pdf-processing-219114/patents_all_english...   \n",
       "\n",
       "                                                text  \\\n",
       "0  US010136408B1\\n(12) United States Patent\\nGree...   \n",
       "1  US010143012B2\\n(12) United States Patent\\nStat...   \n",
       "2  Europäisches\\nPatentamt\\nEuropean\\nPatent Offi...   \n",
       "3  Europäisches\\nPatentamt\\nEuropean\\nPatent Offi...   \n",
       "4  US010142921B2\\n(12) United States Patent\\nMcCa...   \n",
       "\n",
       "                            filename  \n",
       "0          us_001.output-1-to-1.json  \n",
       "1          us_047.output-1-to-1.json  \n",
       "2  Espacenet_En51.output-1-to-1.json  \n",
       "3  Espacenet_En38.output-1-to-1.json  \n",
       "4          us_078.output-1-to-1.json  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import abc\n",
    "\n",
    "class MatchFunction(object):\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def __init__(self, kwargs):\n",
    "        return\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def find_match(self, pdf_text, search_value):\n",
    "        # A match function should return a start position and the matched string.\n",
    "        return\n",
    "\n",
    "\n",
    "class GeneralMatch(MatchFunction):    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def find_match(self, pdf_text, search_value):\n",
    "        pdf_text = pdf_text.lower()\n",
    "        search_value = search_value.lower()\n",
    "        \n",
    "        match = re.search(re.compile(search_value), pdf_text)\n",
    "        if match:\n",
    "            start_index = pdf_text.find(match.group(0))\n",
    "            return start_index, match.group(0)\n",
    "\n",
    "        \n",
    "class MatchClassification(MatchFunction):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def find_match(self, pdf_text, search_value):\n",
    "        pdf_text = pdf_text.lower()\n",
    "        search_value = search_value.lower()\n",
    "\n",
    "        search_value = search_value.replace('0', '[0|o|q]')    # To handle OCR issues (0 -> O or Q)\n",
    "        search_value = search_value.replace('7', '[7|z]')      # To handle OCR issues (7 -> Z)\n",
    "        search_value = search_value.replace('6', '[6|o]')      # To handle OCR issues (6 -> O)\n",
    "        search_value = search_value.replace('q ', '[q|0]\\s')   # To handle OCR issues (Q_ -> 0_)      \n",
    "        search_value = search_value.replace('/', '[/|1|7|\\.]') # To handle OCR issues (/ -> 1 or 7 or .)\n",
    "\n",
    "        match = re.search(re.compile(search_value), pdf_text)\n",
    "        if match:\n",
    "            start_index = pdf_text.find(match.group(0))\n",
    "            return start_index, match.group(0)\n",
    "\n",
    "assert MatchClassification().find_match('H04W 48/18', 'H04W 48/18')[1] == 'H04W 48/18'.lower()\n",
    "assert MatchClassification().find_match('H04W 48118', 'H04W 48/18')[1] == 'H04W 48118'.lower()\n",
    "\n",
    "\n",
    "class MatchClassification_v2(MatchFunction):\n",
    "    \"\"\"Matching function specific to classification_1.\n",
    "    \n",
    "    This field is more complicated as it is sometimes equal to classification 2\n",
    "      or a substring of classification_2, therefore a simple match might give the wrong\n",
    "      location.\n",
    "    \n",
    "    When we get several match, we return the first match after the position of IntCl\n",
    "      for classification 1 and the the position after US CL for classification 2.\n",
    "      \n",
    "    Note: we use either 'Int\\.? C[I|L|1]' or 'U.S. C[I|L|1]' as keyword pattern.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, pattern_keyword_before):\n",
    "        self._pattern_keyword_before = pattern_keyword_before.lower()\n",
    "    \n",
    "    def _find_position_pattern(self, pdf_text):\n",
    "        match = re.search(re.compile(self._pattern_keyword_before), pdf_text)\n",
    "        if match:\n",
    "            start_index = pdf_text.find(match.group(0))\n",
    "            return start_index\n",
    "    \n",
    "    def find_match(self, pdf_text, search_value):\n",
    "        \n",
    "        pdf_text = pdf_text.lower()\n",
    "        search_value = search_value.lower()\n",
    "        search_value = search_value.replace('0', '[0|o|q]')    # To handle OCR issues (0 -> O or Q)\n",
    "        search_value = search_value.replace('7', '[7|z]')      # To handle OCR issues (7 -> Z)\n",
    "        search_value = search_value.replace('6', '[6|o]')      # To handle OCR issues (6 -> O)\n",
    "        search_value = search_value.replace('q ', '[q|0]\\s')   # To handle OCR issues (Q_ -> 0_)      \n",
    "        search_value = search_value.replace('/', '[/|1|7|\\.]') # To handle OCR issues (/ -> 1 or 7 or .)\n",
    "\n",
    "        \n",
    "        position_pattern = self._find_position_pattern(pdf_text)\n",
    "        if position_pattern:\n",
    "            for match in re.finditer(re.compile(search_value), pdf_text):\n",
    "                if match.start() > position_pattern:\n",
    "                    return match.start(), match.group()\n",
    "\n",
    "class MatchTypo(MatchFunction):\n",
    "    \n",
    "    def __init__(self, tolerance=2):\n",
    "        self._tolerance = tolerance\n",
    "    \n",
    "    def find_match(self, pdf_text, search_value):       \n",
    "        pdf_text = pdf_text.lower()\n",
    "        search_value = search_value.lower()\n",
    "\n",
    "        r = regex.compile('(%s){e<=%i}'%(search_value, self._tolerance), flags=regex.BESTMATCH)\n",
    "        match = r.search(pdf_text)\n",
    "        if match:\n",
    "            match_value = match.group(0)\n",
    "            start_index = pdf_text.find(match_value)\n",
    "            return start_index, match_value\n",
    "\n",
    "assert MatchTypo().find_match('I am Flavien Prost in Google', 'Flavien Prost')[1] == 'flavien prost'\n",
    "assert MatchTypo().find_match('I am Flavien Prost in Google', 'Flavian Prost')[1] == 'flavien prost'\n",
    "assert MatchTypo().find_match('I am Flavien Prost in Google', 'Flavian Qrt') is None\n",
    "\n",
    "\n",
    "class MatchApplicant(MatchFunction):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def find_match(self, pdf_text, search_value):\n",
    "        pdf_text = pdf_text.lower()\n",
    "        search_value = search_value.lower()\n",
    "\n",
    "        search_value = search_value.replace(';', '[;|:]')\n",
    "        search_value = search_value.replace('(', '\\(').replace(')', '\\)')\n",
    "\n",
    "        match = re.search(re.compile(search_value), pdf_text)\n",
    "        if match:\n",
    "            start_index = pdf_text.find(match.group(0))\n",
    "            return start_index, match.group(0)\n",
    "\n",
    "# allow OCR to give : instead of ;\n",
    "assert MatchApplicant().find_match('Dikla Dotan-Cohen, Herzliya (IL);', \n",
    "                                   'Dikla Dotan-Cohen, Herzliya (IL);')[1] == 'Dikla Dotan-Cohen, Herzliya (IL);'.lower()\n",
    "assert MatchApplicant().find_match('Dikla Dotan-Cohen, Herzliya (IL):', \n",
    "                                   'Dikla Dotan-Cohen, Herzliya (IL);')[1] == 'Dikla Dotan-Cohen, Herzliya (IL):'.lower()\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIST_FIELDS = {\n",
    "    'publication_date': GeneralMatch(),\n",
    "    'classification_1': MatchClassification_v2(pattern_keyword_before='Int\\.? C[I|L|1]'),\n",
    "    'classification_2': MatchClassification_v2(pattern_keyword_before='U.S. C[I|L|1]'),\n",
    "    'application_number': GeneralMatch(),\n",
    "    'filing_date': MatchTypo(tolerance=1),\n",
    "    'applicant': MatchTypo(),\n",
    "    'inventor': MatchTypo(),\n",
    "    'publication_number': GeneralMatch(),\n",
    "    'priority': GeneralMatch(),\n",
    "    'representative': GeneralMatch(),\n",
    "    'titleFL': MatchTypo(),\n",
    "    'titleSL': MatchTypo(),\n",
    "    #'abstractFL': MatchTypo(),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "publication_number: 0.9895833333333334\n",
      "publication_date: 1.0\n",
      "classification_2: 0.9791666666666666\n",
      "priority: 1.0\n",
      "titleSL: 1.0\n",
      "application_number: 1.0\n",
      "titleFL: 0.9795918367346939\n",
      "applicant: 1.0\n",
      "classification_1: 0.9846938775510204\n",
      "filing_date: 1.0\n",
      "inventor: 0.9897959183673469\n",
      "representative: 0.9270833333333334\n"
     ]
    }
   ],
   "source": [
    "for field  in LIST_FIELDS:\n",
    "    match_fn = LIST_FIELDS[field]\n",
    "\n",
    "    count_value_found = 0\n",
    "    count_value_not_found = 0\n",
    "    for _index in range(0, len(pdf_df)):\n",
    "    \n",
    "        _pdf_file = list(pdf_df['filename'])[_index].replace('.output-1-to-1.json', '.pdf')\n",
    "            \n",
    "        _text = list(pdf_df['text'])[_index]#.decode('utf-8')   #python3 issue?\n",
    "        \n",
    "        # Grab the value from ground truth\n",
    "        selected_df = df_truth[df_truth['file_name']==_pdf_file]\n",
    "        if len(selected_df) != 1:\n",
    "            continue\n",
    "        else:\n",
    "            _field_value_in_truth = selected_df[field].iloc[0]\n",
    "        \n",
    "        if isinstance(_field_value_in_truth, float) and math.isnan(_field_value_in_truth):\n",
    "            continue\n",
    "        \n",
    "        match = match_fn.find_match(_text, _field_value_in_truth)\n",
    "        if match:\n",
    "            found_match = True\n",
    "        else:\n",
    "            found_match = False\n",
    "            #print(_pdf_file)\n",
    "            #print(\"....................\")\n",
    "            #print(_text)\n",
    "            #print(\"....................\")\n",
    "            #print(_field_value_in_truth)\n",
    "            #print(\"....................\")\n",
    "            #print(\"....................\")\n",
    "\n",
    "        count_value_found += int(found_match)\n",
    "        count_value_not_found += int(not found_match)\n",
    "    \n",
    "    recall = float(count_value_found)/ (count_value_found + count_value_not_found)\n",
    "    print ('{}: {}'.format(field, recall))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Construct JSONL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_jsonsl(pdf_text, value_dict):\n",
    "    \"\"\"Constructs the jsonl for a given pdf.\n",
    "    \n",
    "    Args:\n",
    "      pdf_text: Text of the pdf.\n",
    "      value_dict: a dictionary of fieldname: fieldvalue.\n",
    "    \"\"\"\n",
    "    \n",
    "    pdf_text = pdf_text.replace('\"', '')\n",
    "    jsonl = ['''{\"annotations\": [''']\n",
    "    for field in value_dict:\n",
    "        value_to_find = value_dict[field]\n",
    "        \n",
    "        if isinstance(value_to_find, float) and math.isnan(value_to_find):\n",
    "            continue\n",
    "            \n",
    "        match_fn = LIST_FIELDS[field]\n",
    "        match = match_fn.find_match(pdf_text, value_to_find)\n",
    "        if match:\n",
    "          start_index, match_value = match\n",
    "          if (start_index != -1):\n",
    "            end_index = start_index + len(match_value)\n",
    "            jsonl.append('''{{\"text_extraction\": {{\"text_segment\": {{\"end_offset\": {}, \"start_offset\": {}}}}},\"display_name\": \"{}\"}},'''.format(\n",
    "                end_index, start_index, field))\n",
    "\n",
    "    \n",
    "    jsonl[-1] = jsonl[-1].replace('\"},', '\"}') # Remove last comma\n",
    "    jsonl.append(u'''],\"text_snippet\":{{\"content\": \"{}\"}}}}'''.format(pdf_text.replace('\\n', '\\\\n')))\n",
    "    \n",
    "    jsonl_final = ''.join(jsonl)\n",
    "    return jsonl_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196\n"
     ]
    }
   ],
   "source": [
    "LIST_JSONL = []\n",
    "\n",
    "for _index in range(0, len(pdf_df)):\n",
    "\n",
    "    _pdf_file = list(pdf_df['filename'])[_index].replace('.output-1-to-1.json', '.pdf')\n",
    "    _text = list(pdf_df['text'])[_index]#.decode('utf-8')\n",
    "    \n",
    "    selected_df = df_truth[df_truth['file_name']==_pdf_file]\n",
    "    if len(selected_df) != 1:\n",
    "        continue\n",
    "        \n",
    "    jsonl = create_jsonsl(\n",
    "        _text,\n",
    "        {_field: dict(selected_df)[_field].iloc[0] for _field in dict(selected_df) if _field in LIST_FIELDS}\n",
    "    )\n",
    "    LIST_JSONL.append(jsonl)\n",
    "    \n",
    "print (len(LIST_JSONL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['{\"annotations\": [{\"text_extraction\": {\"text_segment\": {\"end_offset\": 730, \"start_offset\": 710}},\"display_name\": \"titleSL\"},{\"text_extraction\": {\"text_segment\": {\"end_offset\": 121, \"start_offset\": 108}},\"display_name\": \"publication_date\"},{\"text_extraction\": {\"text_segment\": {\"end_offset\": 758, \"start_offset\": 747}},\"display_name\": \"applicant\"},{\"text_extraction\": {\"text_segment\": {\"end_offset\": 1235, \"start_offset\": 1224}},\"display_name\": \"classification_2\"},{\"text_extraction\": {\"text_segment\": {\"end_offset\": 1114, \"start_offset\": 1107}},\"display_name\": \"application_number\"},{\"text_extraction\": {\"text_segment\": {\"end_offset\": 709, \"start_offset\": 687}},\"display_name\": \"titleFL\"},{\"text_extraction\": {\"text_segment\": {\"end_offset\": 83, \"start_offset\": 73}},\"display_name\": \"publication_number\"},{\"text_extraction\": {\"text_segment\": {\"end_offset\": 1165, \"start_offset\": 1155}},\"display_name\": \"classification_1\"},{\"text_extraction\": {\"text_segment\": {\"end_offset\": 1140, \"start_offset\": 1127}},\"display_name\": \"filing_date\"},{\"text_extraction\": {\"text_segment\": {\"end_offset\": 758, \"start_offset\": 747}},\"display_name\": \"inventor\"}],\"text_snippet\":{\"content\": \"US010136408B1\\\\n(12) United States Patent\\\\nGreen et al.\\\\n(10) Patent No.: US 10,136,408 B1\\\\n(45) Date of Patent: Nov. 20, 2018\\\\n2009/0261197 A1* 10/2009 Cox ................... B64C 25/36\\\\n244/50\\\\n2010/0153218 A1* 6/2010 Wilson ...... G06Q 30/02\\\\n705/14.72\\\\n2014/0018111 A1* 1/2014 Farley ........... H04W 4/023\\\\n455/456.6\\\\n2015/0126148 A1* 5/2015 Hong\\\\nH04W 4/02\\\\n455/405\\\\n2016/0019499 Al* 1/2016 Bhalodia ............ G06Q 10/0833\\\\n705/40\\\\n2016/0132046 A1* 5/2016 Beoughter ........ G06F 17/30554\\\\n700/17\\\\n2017/0078315 A1* 3/2017 Allen ............... G06F 17/30598\\\\n2017/0300836 A1* 10/2017 Byrne\\\\n.......... G06Q 10/02\\\\n2018/0082260 A1* 3/2018 Dunn ................. G06Q 10/1093\\\\n* cited by examiner\\\\n(54) DETERMINING HIGH VALUE\\\\nGEOGRAPHIC LOCATIONS\\\\n(71) Applicants:Colby Green, Raleigh, NC (US);\\\\nAndrew Schrader, Raleigh, NC (US);\\\\nVamshi Guduguntla, Raleigh, NC (US)\\\\n(72) Inventors: Colby Green, Raleigh, NC (US);\\\\nAndrew Schrader, Raleigh, NC (US);\\\\nVamshi Guduguntla, Raleigh, NC (US)\\\\n(*) Notice: Subject to any disclaimer, the term of this\\\\npatent is extended or adjusted under 35\\\\nU.S.C. 154(b) by 0 days.\\\\n(21) Appl. No.: 15/679,694\\\\n(22) Filed: Aug. 17, 2017\\\\n(51) Int. Cl.\\\\nH04W 64/00\\\\n(2009.01)\\\\nH04W 4/029 (2018.01)\\\\n(52) U.S. CI.\\\\nCPC ........ H04W 64/003 (2013.01); H04W 4/029\\\\n(2018.02)\\\\n(58) Field of Classification Search\\\\nCPC\\\\n........ H04W 64/003; H04W 4/028\\\\nUSPC .............. 455/456.2; 340/524; 701/424, 521\\\\nSee application file for complete search history.\\\\n(56)\\\\nReferences Cited\\\\nU.S. PATENT DOCUMENTS\\\\nPrimary Examiner — Inder P Mehra\\\\n(74) Attorney, Agent, or Firm — John L. Sotomayor\\\\n(57)\\\\nABSTRACT\\\\nThe present invention is a method and system of determin-\\\\ning and assigning a geographic location such as a work or\\\\nhome location to the owner or user of a mobile device.\\\\nMobile devices such as smart phones, tablets, internet com-\\\\nputers, and other hand held mobile devices may be prefer-\\\\nentially targeted for ads based upon the geographic location\\\\nof the owner or user of the mobile device. The home or work\\\\nlocation is determined based upon startup events associated\\\\nwith the mobile device as tracked by startup activations of\\\\nthe mobile device, beacon activations, tile activations, or\\\\nany other Bluetooth or near field communication device\\\\nactivation, during either day time or night time hours.\\\\n2007/0178909 Al*\\\\n2009/0213557 Al*\\\\n8/2007 Doyle ............... GOIS 5/0027\\\\n455/456.1\\\\n8/2009 Wen ...\\\\nH04R 1/406\\\\n361/748\\\\n.\\\\n..\\\\n15 Claims, 3 Drawing Sheets\\\\n300\\\\nSTARTUP EVENT\\\\nOCCURS\\\\n304\\\\nLOCATION 1\\\\nLOCATION 2\\\\nLOCATION 3\\\\n3082\\\\n312\\\\nNO\\\\nLOCATION\\\\nAND\\\\nSTARTUP\\\\nDATA\\\\nTHRESHOLD\\\\nMET?\\\\n320\\\\n316\\\\nUPDATE MOBILE DEVICE\\\\nWITH HOME OR WORK\\\\nLOCATION DATA\\\\nCOLLECT ADDITIONAL\\\\nSTARTUP EVENTS\\\\n\"}}',\n",
       " '{\"annotations\": [{\"text_extraction\": {\"text_segment\": {\"end_offset\": 191, \"start_offset\": 156}},\"display_name\": \"titleSL\"},{\"text_extraction\": {\"text_segment\": {\"end_offset\": 123, \"start_offset\": 110}},\"display_name\": \"publication_date\"},{\"text_extraction\": {\"text_segment\": {\"end_offset\": 444, \"start_offset\": 412}},\"display_name\": \"applicant\"},{\"text_extraction\": {\"text_segment\": {\"end_offset\": 248, \"start_offset\": 236}},\"display_name\": \"classification_2\"},{\"text_extraction\": {\"text_segment\": {\"end_offset\": 1219, \"start_offset\": 1212}},\"display_name\": \"application_number\"},{\"text_extraction\": {\"text_segment\": {\"end_offset\": 155, \"start_offset\": 129}},\"display_name\": \"titleFL\"},{\"text_extraction\": {\"text_segment\": {\"end_offset\": 85, \"start_offset\": 75}},\"display_name\": \"publication_number\"},{\"text_extraction\": {\"text_segment\": {\"end_offset\": 2295, \"start_offset\": 2285}},\"display_name\": \"classification_1\"},{\"text_extraction\": {\"text_segment\": {\"end_offset\": 1232, \"start_offset\": 1220}},\"display_name\": \"filing_date\"},{\"text_extraction\": {\"text_segment\": {\"end_offset\": 542, \"start_offset\": 528}},\"display_name\": \"inventor\"}],\"text_snippet\":{\"content\": \"US010143012B2\\\\n(12) United States Patent\\\\nStattin et al.\\\\n(10) Patent No.: US 10,143,012 B2\\\\n(45) Date of Patent: Nov. 27, 2018\\\\n(54) RANDOM ACCESS PROCEDURE IN\\\\nWIRELESS DEVICE, RADIO BASE STATION\\\\nAND METHODS THEREIN\\\\n(52) U.S. CI.\\\\nCPC ..... H04W 74/0833 (2013.01); H04L 41/0654\\\\n(2013.01); H04W 74/08 (2013.01)\\\\n(58) Field of Classification Search\\\\nNone\\\\nSee application file for complete search history.\\\\n(71)\\\\nApplicant: Telefonaktiebolaget L M Ericsson\\\\n(publ), Stockholm (SE)\\\\n(56)\\\\nReferences Cited\\\\nU.S. PATENT DOCUMENTS\\\\n(72) Inventors: Magnus Stattin, Upplands Väsby (SE);\\\\nGunnar Bergquist, Kista (SE); Tao\\\\nCui, Upplands Väsby (SE); Mats Folke,\\\\nVällingby (SE); Gunnar Mildh,\\\\nSollentuna (SE); Elena Myhre, Järfälla\\\\n(SE); Mikael Wittberg, Uppsala (SE)\\\\n2009/0186624 Al*\\\\n2010/0202288 A1*\\\\n7/2009 Cave .................. H04L 1/1887\\\\n455/450\\\\n8/2010 Park\\\\nH04W 48/08\\\\n370/230\\\\n(Continued)\\\\nTak\\\\n.......\\\\n(73) Assignee: Telefonaktiebolaget LM Ericsson\\\\n(publ), Stockholm (SE)\\\\nFOREIGN PATENT DOCUMENTS\\\\n(*) Notice:\\\\nSubject to any disclaimer, the term of this\\\\npatent is extended or adjusted under 35\\\\nU.S.C. 154(b) by 231 days.\\\\nGB\\\\n2461780 A\\\\n1/2010\\\\nOTHER PUBLICATIONS\\\\n(21) Appl. No.:\\\\n(22) PCT Filed:\\\\n(86) PCT No.:\\\\n$ 371 (c)(1),\\\\n(2) Date:\\\\n14/892,690\\\\nMay 21, 2014\\\\nPCT/SE2014/050621\\\\nUnknown, Author, “3GPP TS 36.321 V11.2.0 (Mar. 2013), 3rd\\\\nGeneration Partnership Project; Technical Specification Group Radio\\\\nAccess Network; Evolved Universal Terrestrial Radio Access\\\\n(E-UTRA); Medium Access Control (MAC) protocol specification\\\\n(Release 11), Mar. 2013, pp. 1-56.\\\\n(Continued)\\\\nNov. 20, 2015\\\\n(87) PCT Pub. No.: W02014/189453\\\\nPCT Pub. Date: Nov, 27, 2014\\\\nPrimary Examiner - George C Atkins\\\\n(74) Attorney, Agent, or Firm — Murphy, Bilak &\\\\nHomiller, PLLC\\\\n(65)\\\\nPrior Publication Data\\\\nUS 2016/0105912 A1\\\\nApr. 14, 2016\\\\nRelated U.S. Application Data\\\\n(60) Provisional application No. 61/825,593, filed on May\\\\n21, 2013.\\\\n(57)\\\\nABSTRACT\\\\nEmbodiments herein relate to a wireless device (10) for\\\\nhandling access to a radio base station (12) in a wireless\\\\ncommunication network (1), the wireless device (10) being\\\\nconfigured to:\\\\ninitiate a random access procedure in the wireless com-\\\\nmunication network (1);\\\\ndetermine that a problem with the random access proce-\\\\ndure has occurred when a certain condition is fulfilled;\\\\n(51)\\\\nInt. C1.\\\\nH04W 74/08\\\\nH04L 12/24\\\\nand\\\\n(2009.01)\\\\n(2006.01)\\\\n(Continued)\\\\n-\\\\nr 10\\\\n301. Initiate RA procedure\\\\n302. Select RA\\\\npreamble\\\\n303. Determine problem\\\\nwith RA procedure\\\\n304. Perform an action\\\\n3041. Delay\\\\n3042. Abort\\\\n3043. Stop\\\\n\"}}',\n",
       " '{\"annotations\": [{\"text_extraction\": {\"text_segment\": {\"end_offset\": 159, \"start_offset\": 149}},\"display_name\": \"publication_date\"},{\"text_extraction\": {\"text_segment\": {\"end_offset\": 805, \"start_offset\": 776}},\"display_name\": \"applicant\"},{\"text_extraction\": {\"text_segment\": {\"end_offset\": 549, \"start_offset\": 524}},\"display_name\": \"priority\"},{\"text_extraction\": {\"text_segment\": {\"end_offset\": 268, \"start_offset\": 258}},\"display_name\": \"application_number\"},{\"text_extraction\": {\"text_segment\": {\"end_offset\": 1054, \"start_offset\": 1003}},\"display_name\": \"titleFL\"},{\"text_extraction\": {\"text_segment\": {\"end_offset\": 201, \"start_offset\": 191}},\"display_name\": \"classification_1\"},{\"text_extraction\": {\"text_segment\": {\"end_offset\": 300, \"start_offset\": 290}},\"display_name\": \"filing_date\"},{\"text_extraction\": {\"text_segment\": {\"end_offset\": 985, \"start_offset\": 974}},\"display_name\": \"inventor\"},{\"text_extraction\": {\"text_segment\": {\"end_offset\": 577, \"start_offset\": 566}},\"display_name\": \"representative\"}],\"text_snippet\":{\"content\": \"Europäisches\\\\nPatentamt\\\\nEuropean\\\\nPatent Office\\\\nOffice européen\\\\ndes brevets\\\\nEP 3 402 306 A1\\\\n(11)\\\\nEUROPEAN PATENT APPLICATION\\\\n(12)\\\\nDate of publication:\\\\n14.11.2018 Bulletin 2018/46\\\\n(51) Int Cl.:\\\\nH04W 88/04 (2009.01)\\\\nH04W 76/10 (2018.01)\\\\n(21) Application number: 18179293.8\\\\n(22) Date of filing: 10.09.2013\\\\n(84) Designated Contracting States:\\\\nAL AT BE BG CH CY CZ DE DK EE ES FI FR GB\\\\nGR HR HU IE IS IT LILTLU LV MC MK MT NL NO\\\\nPL PT RO RS SE SI SK SM TR\\\\n• SHIN, Hang-sik\\\\nGyeonggi-do (KR)\\\\n• PARK, Se-jun\\\\nSeoul (KR)\\\\n(30) Priority: 10.09.2012 KR 20120099791\\\\nRepresentative: HGF Limited\\\\nSaviour House\\\\n9 St. Saviourgate\\\\nYork YO1 8NQ (GB)\\\\n(62) Document number(s) of the earlier application(s) in\\\\naccordance with Art. 76 EPC:\\\\n16181807.5 / 3 101 869\\\\n13183817.9 / 2 706 726\\\\n(71) Applicant: Samsung Electronics Co., Ltd.\\\\nGyeonggi-do 16677 (KR)\\\\nRemarks:\\\\nThis application was filed on 22-06-2018 as a\\\\ndivisional application to the application mentioned\\\\nunder INID code 62.\\\\n(72) Inventors:\\\\n• Ko, Jae-woo\\\\nGyeonggi-do (KR)\\\\nCONNECTING TWO DEVICES AND EXECUTING AN APPLICATION\\\\n(57) Amethod for executing an application based on\\\\na connection between devices by automatically connect-\\\\ning devices, and a device, are disclosed. The method\\\\nincludes: detecting, by a device, an occurrence of a first\\\\ncommunication between the device and at least another\\\\ndevice; transmitting connection information which relates\\\\nto a second communication to be performed by the device\\\\nand application information which relates to the device\\\\nto the at least other device via the first communication;\\\\nreceiving information which relates to the second com-\\\\nmunication from the at least other device; establishing,\\\\nbased on the received information, the second commu-\\\\nnication between the device and the at least other device;\\\\nreceiving a control signal which is based on an application\\\\nwhich is executed by the at least other device via the\\\\nsecond communication, and operating the device based\\\\non the received control signal.\\\\nFIG. 1\\\\nSERVER\\\\n-130\\\\n111\\\\nH\\\\nRELAY F110\\\\nEP 3 402 306 A1\\\\n100\\\\n120\\\\nFIRST DEVICE\\\\n-------------\\\\nSECOND DEVICE\\\\nPrinted by Jouve, 75001 PARIS (FR)\\\\n\"}}',\n",
       " '{\"annotations\": [{\"text_extraction\": {\"text_segment\": {\"end_offset\": 1205, \"start_offset\": 1177}},\"display_name\": \"titleSL\"},{\"text_extraction\": {\"text_segment\": {\"end_offset\": 159, \"start_offset\": 149}},\"display_name\": \"publication_date\"},{\"text_extraction\": {\"text_segment\": {\"end_offset\": 877, \"start_offset\": 850}},\"display_name\": \"applicant\"},{\"text_extraction\": {\"text_segment\": {\"end_offset\": 586, \"start_offset\": 558}},\"display_name\": \"priority\"},{\"text_extraction\": {\"text_segment\": {\"end_offset\": 271, \"start_offset\": 261}},\"display_name\": \"application_number\"},{\"text_extraction\": {\"text_segment\": {\"end_offset\": 1176, \"start_offset\": 1099}},\"display_name\": \"titleFL\"},{\"text_extraction\": {\"text_segment\": {\"end_offset\": 203, \"start_offset\": 191}},\"display_name\": \"classification_1\"},{\"text_extraction\": {\"text_segment\": {\"end_offset\": 303, \"start_offset\": 293}},\"display_name\": \"filing_date\"},{\"text_extraction\": {\"text_segment\": {\"end_offset\": 1069, \"start_offset\": 1047}},\"display_name\": \"inventor\"},{\"text_extraction\": {\"text_segment\": {\"end_offset\": 658, \"start_offset\": 637}},\"display_name\": \"representative\"}],\"text_snippet\":{\"content\": \"Europäisches\\\\nPatentamt\\\\nEuropean\\\\nPatent Office\\\\nOffice européen\\\\ndes brevets\\\\n(11)\\\\nEP 3 400 947 A1\\\\n(12)\\\\nEUROPEAN PATENT APPLICATION\\\\nDate of publication:\\\\n14.11.2018 Bulletin 2018/46\\\\n(51) Int Cl.:\\\\nA61K 3117088 (2006.01)\\\\nC12N 15/113 (2010.01)\\\\n(21) Application number: 18179911.5\\\\n(22) Date of filing: 14.02.2014\\\\n(84) Designated Contracting States:\\\\nAL AT BE BG CH CY CZ DE DK EE ES FI FR GB\\\\nGR HR HU IE IS IT LILTLU LV MC MK MT NL NO\\\\nPL PT RO RS SE SI SK SM TR\\\\n• VINEY, Nicholas J.\\\\nCarlsbad, CA 92010 (US)\\\\n• WITZTUM, Joseph L.\\\\nSan Diego, CA 92120 (US)\\\\n(30) Priority: 14.02.2013 US 201361764969 P\\\\n20.09.2013 US 201361880779 P\\\\n(74) Representative: Chapman, Desmond Mark\\\\nCarpmaels & Ransford LLP\\\\nOne Southampton Row\\\\nLondon WC1B 5HA (GB)\\\\n(62) Document number(s) of the earlier application(s) in\\\\naccordance with Art. 76 EPC:\\\\n14751357.6 / 2 956 176\\\\n(71) Applicant: Ionis Pharmaceuticals, Inc.\\\\nCarlsbad, CA 92010 (US)\\\\nRemarks:\\\\nThis application was filed on 26-06-2018 as a\\\\ndivisional application to the application mentioned\\\\nunder INID code 62.\\\\n(72) Inventors:\\\\n• ALEXANDER, Veronica J.\\\\nCarlsbad, CA 92010 (US)\\\\n(54)\\\\nMODULATION OF APOLIPOPROTEIN C-III (APOCIII) EXPRESSION IN LIPOPROTEIN LIPASE\\\\nDEFICIENT (LPLD) POPULATIONS\\\\n(57) Provided herein are methods, compounds, and compositions for reducing expression of ApoCill mRNA and\\\\nprotein in a patient with Fredrickson Type I dyslipidemia, FCS, LPLD. Also provided herein are methods, compounds,\\\\nand compositions for treating, preventing, delaying, or ameliorating Fredrickson Type I dyslipidemia, FCS, LPLD, in a\\\\npatient. Further provided herein are methods, compounds, and compositions for increasing HDL levels and/or improving\\\\nthe ratio of TG to HDL and reducing plasma lipids and plasma glucose in a patient with Fredrickson Type I dyslipidemia,\\\\nFCS, LPLD. Such methods, compounds, and compositions are useful to treat, prevent, delay, or ameliorate any one or\\\\nmore of pancreatitis, cardiovascular disease or metabolic disorder, or a symptom thereof.\\\\nEP 3 400 947 A1\\\\nPrinted by Jouve, 75001 PARIS (FR)\\\\n\"}}',\n",
       " '{\"annotations\": [{\"text_extraction\": {\"text_segment\": {\"end_offset\": 174, \"start_offset\": 154}},\"display_name\": \"titleSL\"},{\"text_extraction\": {\"text_segment\": {\"end_offset\": 123, \"start_offset\": 110}},\"display_name\": \"publication_date\"},{\"text_extraction\": {\"text_segment\": {\"end_offset\": 341, \"start_offset\": 323}},\"display_name\": \"applicant\"},{\"text_extraction\": {\"text_segment\": {\"end_offset\": 2042, \"start_offset\": 2032}},\"display_name\": \"classification_2\"},{\"text_extraction\": {\"text_segment\": {\"end_offset\": 915, \"start_offset\": 908}},\"display_name\": \"application_number\"},{\"text_extraction\": {\"text_segment\": {\"end_offset\": 153, \"start_offset\": 129}},\"display_name\": \"titleFL\"},{\"text_extraction\": {\"text_segment\": {\"end_offset\": 84, \"start_offset\": 74}},\"display_name\": \"publication_number\"},{\"text_extraction\": {\"text_segment\": {\"end_offset\": 1409, \"start_offset\": 1400}},\"display_name\": \"classification_1\"},{\"text_extraction\": {\"text_segment\": {\"end_offset\": 1053, \"start_offset\": 1040}},\"display_name\": \"filing_date\"},{\"text_extraction\": {\"text_segment\": {\"end_offset\": 409, \"start_offset\": 395}},\"display_name\": \"inventor\"}],\"text_snippet\":{\"content\": \"US010142921B2\\\\n(12) United States Patent\\\\nMcCann et al.\\\\n(10) Patent No.: US 10,142,921 B2\\\\n(45) Date of Patent: *Nov. 27, 2018\\\\n(54) WIRELESS NETWORK SERVICE\\\\nTRANSACTION PROTOCOL\\\\n(58)\\\\nField of Classification Search\\\\nCPC .... H04W 48/08; H04W 48/14; H04L 61/1541\\\\nSee application file for complete search history.\\\\n(71) Applicant: BlackBerry Limited, Waterloo (CA)\\\\n(56)\\\\nReferences Cited\\\\n(72) Inventors: Stephen McCann, Southampton (GB);\\\\nMichael Peter Montemurro, Toronto\\\\n(CA)\\\\nU.S. PATENT DOCUMENTS\\\\n(73) Assignee: BlackBerry Limited, Waterloo, Ontario\\\\n(CA)\\\\n6,493,561 B1 12/2002 Hasegawa\\\\n7,010,305 B23/2006 Immonen et al.\\\\n(Continued)\\\\nFOREIGN PATENT DOCUMENTS\\\\n(*) Notice:\\\\nSubject to any disclaimer, the term of this\\\\npatent is extended or adjusted under 35\\\\nU.S.C. 154(b) by 0 days.\\\\nCN\\\\n1893396 A 1/2007\\\\n1969529 A 5/2007\\\\n(Continued)\\\\nThis patent is subject to a terminal dis-\\\\nclaimer.\\\\nOTHER PUBLICATIONS\\\\n(21)\\\\nAppl. No.: 15/483,759\\\\nWi-Fi Alliance; “Wi-Fi Peer-to-Peer (P2P) Technical Specifica-\\\\ntion”; Version 1.2; 2010; 159 pages.\\\\n(Continued)\\\\n(22) Filed: Apr. 10, 2017\\\\n(65)\\\\nPrior Publication Data\\\\nUS 2017/0215129 A1 Jul. 27, 2017\\\\nRelated U.S. Application Data\\\\n(63) Continuation of application No. 14/854,685, filed on\\\\nSep. 15, 2015, now Pat. No. 9,622,155, which is a\\\\n(Continued)\\\\nPrimary Examiner — Farah Faroul\\\\n(74) Attorney, Agent, or Firm — Conley Rose, P.C.; J.\\\\nRobert Brown, Jr.; Gayatry S. Nair\\\\n(51)\\\\nInt. CI.\\\\nH04W 4/00\\\\nH04W 48/14\\\\n(57)\\\\nABSTRACT\\\\nA mobile device may retrieve service information about a\\\\nnetwork prior to associating with the network. Utilizing an\\\\nadvertisement protocol to transmit service query messages,\\\\na mobile device may receive service query responses from\\\\na network that identify the services available prior to estab-\\\\nlishing network capability. In other words, the messaging is\\\\nprior to the exchange of any authentication parameters\\\\nbetween the device and the network as well prior to the\\\\nestablishment of a recognized session between the device\\\\nand the network.\\\\n(2018.01)\\\\n(2009.01)\\\\n(Continued)\\\\n(52) U.S. CI.\\\\nCPC ....\\\\nH04W 48/14 (2013.01); G06F 21/606\\\\n(2013.01); H04L 61/1541 (2013.01);\\\\n(Continued)\\\\n28 Claims, 8 Drawing Sheets\\\\n3057\\\\nNetwork\\\\nWLAN\\\\nService\\\\nQuery\\\\nMessages\\\\nAP(S)\\\\nService\\\\nTransaction\\\\nProxy (TPX) i\\\\n--\\\\nPre-association\\\\n114\\\\n\"}}']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LIST_JSONL[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload JSONL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_jsonl_content(jsonl, full_gcs_path): \n",
    "    \n",
    "    bucket_name, blob_name = get_bucket_blob(full_gcs_path)\n",
    "    \n",
    "    client = storage.Client.from_service_account_json(SERVICE_ACCOUNT_PATH)\n",
    "    bucket = client.get_bucket(bucket_name)\n",
    "    blob_csv = bucket.blob(blob_name)\n",
    "\n",
    "    blob_csv.upload_from_string(jsonl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_jsonl_content(\n",
    "    \"\\n\".join(LIST_JSONL), 'gs://modeling-work-v1/ner_model/all_english_022.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IF YOU WANT TO SPLIT YOURSELF\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# #Split train test and validation jsonl files\n",
    "# X_train, X_test = train_test_split(LIST_JSONL,test_size=0.2, random_state=42)\n",
    "# X_validation, X_test = train_test_split(X_test, test_size=0.5, random_state=42)\n",
    "\n",
    "# save_jsonl_content(\"\\n\".join(X_train), 'gs://modeling-work-v1/ner_model/train_0207.jsonl')\n",
    "# save_jsonl_content(\"\\n\".join(X_validation), 'gs://modeling-work-v1/ner_model/eval_0207.jsonl')\n",
    "# save_jsonl_content(\"\\n\".join(X_test), 'gs://modeling-work-v1/ner_model/test_0207.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "LIST_JSONL[30:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content(gcs_path):\n",
    "    match = re.match(r'gs://([^/]+)/(.+)', gcs_path) # split bucket/path\n",
    "    bucket_name = match.group(1)\n",
    "    prefix = match.group(2)\n",
    "    client = storage.Client()\n",
    "    content_dict = {}  \n",
    "    bucket = client.get_bucket(bucket_name)\n",
    "\n",
    "    blob_list = list(bucket.list_blobs(prefix=prefix))\n",
    "    for blob in blob_list:\n",
    "        gcs_uris_list = []\n",
    "        JSON_PATH = os.path.join('gs://', blob.bucket.name, blob.name)\n",
    "        content_dict[JSON_PATH] = vis_b_v1p2_json_path_to_text(JSON_PATH)\n",
    "    return content_dict     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'gs://pdf-processing-219114/patents_test_fprost/json/us_047.output-1-to-1.json'\n",
    "x = get_content(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "US010143012B2\n",
      "(12) United States Patent\n",
      "Stattin et al.\n",
      "(10) Patent No.: US 10,143,012 B2\n",
      "(45) Date of Patent: Nov. 27, 2018\n",
      "(54) RANDOM ACCESS PROCEDURE IN\n",
      "WIRELESS DEVICE, RADIO BASE STATION\n",
      "AND METHODS THEREIN\n",
      "(52) U.S. CI.\n",
      "CPC ..... H04W 74/0833 (2013.01); H04L 41/0654\n",
      "(2013.01); H04W 74/08 (2013.01)\n",
      "(58) Field of Classification Search\n",
      "None\n",
      "See application file for complete search history.\n",
      "(71)\n",
      "Applicant: Telefonaktiebolaget L M Ericsson\n",
      "(publ), Stockholm (SE)\n",
      "(56)\n",
      "References Cited\n",
      "U.S. PATENT DOCUMENTS\n",
      "(72) Inventors: Magnus Stattin, Upplands Väsby (SE);\n",
      "Gunnar Bergquist, Kista (SE); Tao\n",
      "Cui, Upplands Väsby (SE); Mats Folke,\n",
      "Vällingby (SE); Gunnar Mildh,\n",
      "Sollentuna (SE); Elena Myhre, Järfälla\n",
      "(SE); Mikael Wittberg, Uppsala (SE)\n",
      "2009/0186624 Al*\n",
      "2010/0202288 A1*\n",
      "7/2009 Cave .................. H04L 1/1887\n",
      "455/450\n",
      "8/2010 Park\n",
      "H04W 48/08\n",
      "370/230\n",
      "(Continued)\n",
      "Tak\n",
      ".......\n",
      "(73) Assignee: Telefonaktiebolaget LM Ericsson\n",
      "(publ), Stockholm (SE)\n",
      "FOREIGN PATENT DOCUMENTS\n",
      "(*) Notice:\n",
      "Subject to any disclaimer, the term of this\n",
      "patent is extended or adjusted under 35\n",
      "U.S.C. 154(b) by 231 days.\n",
      "GB\n",
      "2461780 A\n",
      "1/2010\n",
      "OTHER PUBLICATIONS\n",
      "(21) Appl. No.:\n",
      "(22) PCT Filed:\n",
      "(86) PCT No.:\n",
      "$ 371 (c)(1),\n",
      "(2) Date:\n",
      "14/892,690\n",
      "May 21, 2014\n",
      "PCT/SE2014/050621\n",
      "Unknown, Author, “3GPP TS 36.321 V11.2.0 (Mar. 2013)\", 3rd\n",
      "Generation Partnership Project; Technical Specification Group Radio\n",
      "Access Network; Evolved Universal Terrestrial Radio Access\n",
      "(E-UTRA); Medium Access Control (MAC) protocol specification\n",
      "(Release 11), Mar. 2013, pp. 1-56.\n",
      "(Continued)\n",
      "Nov. 20, 2015\n",
      "(87) PCT Pub. No.: W02014/189453\n",
      "PCT Pub. Date: Nov, 27, 2014\n",
      "Primary Examiner - George C Atkins\n",
      "(74) Attorney, Agent, or Firm — Murphy, Bilak &\n",
      "Homiller, PLLC\n",
      "(65)\n",
      "Prior Publication Data\n",
      "US 2016/0105912 A1\n",
      "Apr. 14, 2016\n",
      "Related U.S. Application Data\n",
      "(60) Provisional application No. 61/825,593, filed on May\n",
      "21, 2013.\n",
      "(57)\n",
      "ABSTRACT\n",
      "Embodiments herein relate to a wireless device (10) for\n",
      "handling access to a radio base station (12) in a wireless\n",
      "communication network (1), the wireless device (10) being\n",
      "configured to:\n",
      "initiate a random access procedure in the wireless com-\n",
      "munication network (1);\n",
      "determine that a problem with the random access proce-\n",
      "dure has occurred when a certain condition is fulfilled;\n",
      "(51)\n",
      "Int. C1.\n",
      "H04W 74/08\n",
      "H04L 12/24\n",
      "and\n",
      "(2009.01)\n",
      "(2006.01)\n",
      "(Continued)\n",
      "-\n",
      "r 10\n",
      "301. Initiate RA procedure\n",
      "302. Select RA\n",
      "preamble\n",
      "303. Determine problem\n",
      "with RA procedure\n",
      "304. Perform an action\n",
      "3041. Delay\n",
      "3042. Abort\n",
      "3043. Stop\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (x[file])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdf_env_3.5",
   "language": "python",
   "name": "pdf_env_3.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
